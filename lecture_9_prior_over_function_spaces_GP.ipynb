{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Introduction to Gaussian Processes.\n",
    "\n",
    "$\n",
    "% DEFINITIONS\n",
    "\\newcommand{\\bff}{\\mathbf{f}}\n",
    "\\newcommand{\\bm}{\\mathbf{m}}\n",
    "\\newcommand{\\bk}{\\mathbf{k}}\n",
    "\\newcommand{\\bx}{\\mathbf{x}}\n",
    "\\newcommand{\\by}{\\mathbf{y}}\n",
    "\\newcommand{\\bz}{\\mathbf{z}}\n",
    "\\newcommand{\\bA}{\\mathbf{A}}\n",
    "\\newcommand{\\bB}{\\mathbf{B}}\n",
    "\\newcommand{\\bC}{\\mathbf{C}}\n",
    "\\newcommand{\\bD}{\\mathbf{D}}\n",
    "\\newcommand{\\bI}{\\mathbf{I}}\n",
    "\\newcommand{\\bK}{\\mathbf{K}}\n",
    "\\newcommand{\\bL}{\\mathbf{L}}\n",
    "\\newcommand{\\bM}{\\mathbf{M}}\n",
    "\\newcommand{\\bX}{\\mathbf{X}}\n",
    "\\newcommand{\\bLambda}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\bSigma}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\bmu}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\calN}{\\mathcal{N}}\n",
    "\\newcommand{\\R}{\\mathbb{R}}\n",
    "\\newcommand{\\E}{\\mathbb{E}}\n",
    "\\newcommand{\\C}{\\mathbb{C}}\n",
    "\\newcommand{\\Rd}{\\R^d}\n",
    "\\newcommand{\\Rdd}{\\R^{d\\times d}}\n",
    "\\newcommand{\\bzero}{\\mathbf{0}}\n",
    "\\newcommand{\\GP}{\\mbox{GP}}\n",
    "% END OF DEFINITIONS\n",
    "$\n",
    "In many engineering problems we have to deal with functions that are unknown.\n",
    "For example, in oil reservoir modeling, the permeability tensor $\\bK(\\bx)$ or the porosity $\\phi(\\bx)$ of\n",
    "the ground are, generally, unknown quantities.\n",
    "Therefore, we would like to treat them as if they where random.\n",
    "That is, we have to talk about probabilities on function spaces.\n",
    "Such a thing is achieved via the theory of *random fields*.\n",
    "However, instead of developing the generic mathematical theory of random fields,\n",
    "we concentrate on a special class of random fields, the *Gaussian random fields*\n",
    "or *Gaussian processes*.\n",
    "\n",
    "A Gaussian process (GP) is a generalization of a multivariate Gaussian distribution to\n",
    "*infinite* dimensions.\n",
    "It essentially defines a probability measure on a function space.\n",
    "When we say that $f(\\cdot)$ is a GP, we mean that it is a random variable that is actually\n",
    "a function.\n",
    "Mathematically, we write:\n",
    "\\begin{equation}\n",
    "f(\\cdot) | m(\\cdot), k(\\cdot, \\cdot) \\sim \\GP\\left(f(\\cdot) | m(\\cdot), k(\\cdot, \\cdot) \\right),\n",
    "\\end{equation}\n",
    "where \n",
    "$m:\\Rd\\rightarrow R$ is the *mean function* and \n",
    "$k:\\Rd\\times\\Rd\\rightarrow\\R$ is the *covariance function*.\n",
    "So, compared to a multivariate normal we have:\n",
    "\n",
    "+ A random function $f(\\cdot)$ instead of a random vector $\\bx$.\n",
    "+ A mean function $m(\\cdot)$ instead of a mean vector $\\bmu$.\n",
    "+ A covariance function $k(\\cdot,\\cdot)$ instead of a covariance matrix $\\bSigma$.\n",
    "\n",
    "But, what does this definition actually mean? Actually, it gets its meaning from the multivariate Gaussian distribution. Here is how: \n",
    "\n",
    "+ Let $\\bx_1,\\dots,\\bx_n$ be $n$ points in $\\R^d$. To keep the notation down, let us arrange these\n",
    "points in an $n\\times d$ matrix:\n",
    "\\begin{equation}\n",
    "\\bX =\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "\\bx_1\\\\\n",
    "\\vdots\\\\\n",
    "\\bx_n\n",
    "\\end{array}\n",
    "\\right).\n",
    "\\end{equation}\n",
    "+ Let $\\bff\\in\\R^n$ be the outputs of $f(\\cdot)$ on each one of the rows of $\\bX$, i.e.,\n",
    "\\begin{equation}\n",
    "\\bff =\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "f(\\bx_1)\\\\\n",
    "\\vdots\\\\\n",
    "f(\\bx_n)\n",
    "\\end{array}\n",
    "\\right).\n",
    "\\end{equation}\n",
    "+ The fact that $f(\\cdot)$ is a GP with mean and covariance function $m(\\cdot)$ and $k(\\cdot,\\cdot)$, respectively, *means* that the vector of outputs $\\bff$ at\n",
    "the arbitrary inputs in $\\bX$ is the following multivariate-normal:\n",
    "\\begin{equation}\n",
    "\\bff | \\bX, m(\\cdot), k(\\cdot, \\cdot) \\sim \\calN\\left(\\bff | \\bm(\\bX), \\bk(\\bX, \\bX) \\right),\n",
    "\\end{equation}\n",
    "with mean vector:\n",
    "$$\n",
    "\\bm(\\bX) =\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "m(\\bx_1)\\\\\n",
    "\\vdots\\\\\n",
    "m(\\bx_n)\n",
    "\\end{array}\n",
    "\\right),\n",
    "$$\n",
    "and covariance matrix:\n",
    "$$\n",
    "\\bk(\\bX, \\bX) = \\left(\n",
    "\\begin{array}{ccc}\n",
    "k(\\bx_1,\\bx_1) & \\dots & k(\\bx_1, \\bx_n)\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "k(\\bx_n, \\bx_1) & \\dots & k(\\bx_n, \\bx_n)\n",
    "\\end{array}\n",
    "\\right).\n",
    "$$\n",
    "\n",
    "\n",
    "###1. Priors on function spaces\n",
    "\n",
    "###2. Mean function.\n",
    "\n",
    "\n",
    "## Interpretation of the mean\n",
    "What is the meaning of $m(\\cdot)$?\n",
    "Well, it is quite easy to grasp.\n",
    "For any point $\\bx\\in\\R^d$, $m(\\bx)$ should give us the value we beleive is more probable for \n",
    "$f(\\bx)$.\n",
    "Mathematically, $m(\\bx)$ is nothing more than the expected value of the random variable $f(\\bx)$.\n",
    "That is:\n",
    "\\begin{equation}\n",
    "m(\\bx) = \\mathbb{E}[f(\\bx)].\n",
    "\\end{equation}\n",
    "\n",
    "In practical application, we usually take the mean to be:\n",
    "\n",
    "+ zero, i.e.,\n",
    "$$\n",
    "m(\\bx) = 0.\n",
    "$$\n",
    "\n",
    "+ a constant, i.e.,\n",
    "$$\n",
    "m(\\bx) = c,\n",
    "$$\n",
    "where $c$ is a parameter.\n",
    "\n",
    "+ linear, i.e.,\n",
    "$$\n",
    "m(\\bx) = c_0 + \\sum_{i=1}^dc_ix_i,\n",
    "$$\n",
    "where $c_i, i=0,\\dots,d$ are parameters.\n",
    "\n",
    "+ using a set of $m$ basis functions (generalized linear model), i.e.,\n",
    "$$\n",
    "m(\\bx) = \\sum_{i=1}^mc_i\\phi_i(\\bx),\n",
    "$$\n",
    "where $c_i$ and $\\phi_i(\\cdot)$ are parameters and basis functions.\n",
    "\n",
    "+ and endless other possibilities.\n",
    "\n",
    "## Interpretation of the covariance function\n",
    "What is the meaning of $k(\\cdot, \\cdot)$?\n",
    "This concept is considerably more challenging than the mean.\n",
    "Let's try to break it down:\n",
    "\n",
    "+ Let $\\bx\\in\\Rd$. Then $k(\\bx, \\bx)$ is the variance of the random variable $f(\\bx)$, i.e.,\n",
    "$$\n",
    "\\mathbb{V}[f(\\bx)] = \\mathbb{E}\\left[\\left(f(\\bx) - m(\\bx) \\right)^2 \\right].\n",
    "$$\n",
    "In other words, we beleive that there is about $95\\%$ probability that the value of\n",
    "the random variable $f(\\bx)$ fall within the interval:\n",
    "$$\n",
    "\\left((m(\\bx) - 2\\sqrt{k(\\bx, \\bx)}, m(\\bx) + 2\\sqrt{k(\\bx,\\bx)}\\right).\n",
    "$$\n",
    "\n",
    "+ Let $\\bx,\\bx'\\Rd$. Then $k(\\bx, \\bx')$ tells us how the random variable $f(\\bx)$ and\n",
    "$f(\\bx')$ are correlated. In particular, $k(\\bx,\\bx')$ is equal to the covariance\n",
    "of the random variables $f(\\bx)$ and $f(\\bx')$, i.e.,\n",
    "$$\n",
    "k(\\bx, \\bx') = \\mathbb{C}[f(\\bx), f(\\bx')]\n",
    "= \\mathbb{E}\\left[\n",
    "\\left(f(\\bx) - m(\\bx)\\right)\n",
    "\\left(f(\\bx') - m(\\bx')\\right)\n",
    "\\right].\n",
    "$$\n",
    "\n",
    "## Properties of the covariance function\n",
    "\n",
    "+ There is one property of the covariance function that we can note right away.\n",
    "Namely, that for any $\\bx\\in\\Rd$, $k(\\bx, \\bx) > 0$.\n",
    "This is easly understood by the interpretation of $k(\\bx, \\bx)$ as the variance\n",
    "of the random variable $f(\\bx)$.\n",
    "\n",
    "+ $k(\\bx, \\bx')$ becomes smaller as the distance between $\\bx$ and $\\bx'$ grows.\n",
    "\n",
    "+ For any choice of points $\\bX\\in\\R^{n\\times d}$, the covariance matrix: $\\bK(\\bX, \\bX)$ has\n",
    "to be positive-definite (so that the vector of outputs $\\bff$ is indeed a multivariate\n",
    "normal distribution).\n",
    "\n",
    "\n",
    "###Sampling from a Gaussian Process. \n",
    "\n",
    "**Write about the algorithm to sample from a Gaussian Process here**\n",
    "\n",
    "### Karhunen-Loeve Expansion.\n",
    "\n",
    "###Numerical Approximation to the KL Expansion. \n",
    "\n",
    "**Talk about the Nystrom Approximation**\n",
    "\n",
    "##Elliptic Partial Differential Equation Example. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
